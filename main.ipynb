{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPiJOgGY7XJf4rbBQOT1PIK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OjashKush/RAG-chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv myenv\n",
        "!source myenv/bin/activate\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LvK3sbxCnS4",
        "outputId": "f1ab59e0-a3b4-4922-b1d6-dab40b084bc6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.25.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.1.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mcreated virtual environment CPython3.10.12.final.0-64 in 254ms\n",
            "  creator CPython3Posix(dest=/content/myenv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.3.1, setuptools==69.0.2, wheel==0.42.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UQK_-RsDnU7",
        "outputId": "2832eb95-7026-4078-c36e-d2c06b883f45"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "VDKKVn4xinwu",
        "outputId": "23aa5ebe-7442-4751-a6d0-6eb720c5cdd5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Iterator' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-54b45b2867fe>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# OpenAI is used for the embedding LLM and GenAI model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# used to generate responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Langchain is middleware that ties together the components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxiesTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0medit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mEdit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/edit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompletion_usage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompletionUsage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mHttpxRequestFiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_given\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_datetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_not_given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m from ._compat import (\n\u001b[1;32m     35\u001b[0m     \u001b[0mPYDANTIC_V2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mextract_type_var_from_base\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mextract_type_var_from_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconsume_sync_iterator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconsume_sync_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsume_async_iterator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconsume_async_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m from ._transform import (\n\u001b[1;32m     42\u001b[0m     \u001b[0mPropertyInfo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPropertyInfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_streams.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconsume_sync_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Iterator' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Base Python data handling environment imports\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "# Pinecone is a cloud-based Vector Database we'll use\n",
        "# to store embeddings\n",
        "import pinecone\n",
        "\n",
        "# OpenAI is used for the embedding LLM and GenAI model\n",
        "# used to generate responses\n",
        "import openai\n",
        "\n",
        "# Langchain is middleware that ties together the components\n",
        "# of the embedding and retrieval pipelines\n",
        "\n",
        "# The embedding chain creates searchable vectors of our data\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "# A link in the chain to operate a chat session\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# We'll maintain some memory of the chat so follow-up questions\n",
        "# will be context-sensitive\n",
        "from langchain.chains.conversation.memory \\\n",
        "import ConversationBufferWindowMemory\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_KEY=os.getenv(\"OPENAPI_KEY\")\n",
        "openai.api_key = OPENAI_KEY\n",
        "EMBEDDING_MODEL=\"text-embedding-ada-002\"\n",
        "GENAI_MODEL='gpt-3.5-turbo'\n",
        "\n",
        "PINECONE_KEY=os.getenv(\"PINECONE_KEY\")\n",
        "PINECONE_ENV=\"gcp-starter\"\n",
        "PINECONE_INDEX_NAME=\"default\" # this will be created below"
      ],
      "metadata": {
        "id": "HKKITBjfyPUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://rhkdemo.blob.core.windows.net/demodata/squad-content.tsv\"\n",
        "df = pd.read_csv(URL, sep='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fwD2BxylyTlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "u1xY-sUcyXU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch only context knowledge about Detroit and London\n",
        "filtered_df = df.loc[df['subject'].isin(['Dell'])]\n",
        "print(filtered_df['subject'].value_counts())\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "1_oJrUs6ya3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(api_key = PINECONE_KEY, environment = PINECONE_ENV)\n",
        "index_list = pinecone.list_indexes()\n",
        "if len(index_list) == 0:\n",
        "    print(\"Creating index...\")\n",
        "    pinecone.create_index(PINECONE_INDEX_NAME, dimension=1536, metric='dotproduct')\n",
        "\n",
        "print(pinecone.describe_index(PINECONE_INDEX_NAME))\n",
        "index = pinecone.Index(PINECONE_INDEX_NAME)"
      ],
      "metadata": {
        "id": "XKKOudiayeXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This references the text-embedding-ada-002 OpenAI model we'll use to create embeddings\n",
        "# Both for indexing ground knowledge content, and later when searching ground knowledge\n",
        "# For RAG documents to include in LLM Prompts\n",
        "\n",
        "embed = OpenAIEmbeddings(\n",
        "    model = EMBEDDING_MODEL,\n",
        "    openai_api_key= OPENAI_KEY)"
      ],
      "metadata": {
        "id": "F8YHKazoykOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a for loop to create embeddings for each of the Detroit & London knowledge articles, and\n",
        "# Then add the embeddings and orgiional article text to the vector databse\n",
        "# Shout-out to Dr. KM Moshin for this code snippet from his Excellent Udemy course on Pinecone!\n",
        "batch_size = 20\n",
        "\n",
        "for i in tqdm(range(0, len(filtered_df), batch_size)):\n",
        "    # OpenAPI has rate limits, and we use batches to slow the pace of embedding requests\n",
        "    i_end = min(i+batch_size, len(filtered_df))\n",
        "    batch = filtered_df.iloc[i:i_end]\n",
        "\n",
        "    # When querying the Vector DB for nearest vectors, the metadata\n",
        "    # is what is returned and added to the LLM Prompt (the \"Grounding Knowledge\")\n",
        "    meta_data = [{\"subject\" : row['subject'],\n",
        "              \"context\": row['context']}\n",
        "             for i, row in batch.iterrows()]\n",
        "\n",
        "    # Get a list of documents to submit to OpenAI for embedding\n",
        "    docs = batch['context'].tolist()\n",
        "    emb_vectors = embed.embed_documents(docs)\n",
        "\n",
        "    # The original ID keys are used as the PK in the Vector DB\n",
        "    ids = batch['id'].tolist()\n",
        "\n",
        "    # Add embeddings, associated metadata, and the keys to the vector DB\n",
        "    to_upsert = zip(ids, emb_vectors, meta_data)\n",
        "    index.upsert(vectors=to_upsert)\n",
        "\n",
        "    # Pause for 10 seconds after each batch to avoid rate limits\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "id": "3HO-K7z5ylLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectorstore = Pinecone(index, embed, \"context\")\n",
        "query = \"Who founded Dell?\" #ask some question that's answerable with the content added to the Vector DB\n",
        "vectorstore.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "fiK2eCm5yo8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a reference to the OpenAI LLM\n",
        "llm = ChatOpenAI(openai_api_key = OPENAI_KEY,\n",
        "                model_name = GENAI_MODEL,\n",
        "                temperature = 0.0)\n",
        "\n",
        "# Ensure the chat session includes memory of 5 previous messages\n",
        "conv_mem = ConversationBufferWindowMemory(\n",
        "    memory_key = 'history',\n",
        "    k = 5,\n",
        "    return_messages =True)\n",
        "\n",
        "# Create the chain to manage the chat session\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever = vectorstore.as_retriever())"
      ],
      "metadata": {
        "id": "O43W1eGrywnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now have a conversation about the documents that were added to the grounding data vector database"
      ],
      "metadata": {
        "id": "G_sOP6R8y4Db"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZsyjDIty6ym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}